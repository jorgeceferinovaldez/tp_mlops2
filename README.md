# MaestrÃ­a en Inteligencia Artificial FIUBA

# Trabajo PrÃ¡ctico Integrador - Operaciones de Aprendizaje AutomÃ¡tico II

## API Multiprotocolo de clasificaciÃ³n de estrellas 
**ClasificaciÃ³n de objetos estelares con mÃºltiples protocolos de comunicaciÃ³n**

---

## Integrantes:
- Noelia Qualindi
- Trinidad Monreal 
- Fabian Sarmiento
- Matias Marando
- Jorge Valdez

## Tabla de Contenidos
1. [Dataset y Contexto](#dataset-y-contexto)
2. [Arquitectura del Sistema](#arquitectura-del-sistema)
3. [Nuevas Funcionalidades](#nuevas-funcionalidades)
4. [Estructura del Proyecto](#estructura-del-proyecto)
5. [InstalaciÃ³n y Despliegue](#instalaciÃ³n-y-despliegue)
6. [Uso de la API](#uso-de-la-api)
7. [ComparaciÃ³n de Protocolos](#comparaciÃ³n-de-protocolos)
8. [Testing y Benchmarking](#testing-y-benchmarking)

---

## Dataset y Contexto

**Dataset**: Stellar Classification Dataset - SDSS17 (Sloan Digital Sky Survey)

La API SCO-SDSS17 (Star Classification Objects SDSS) clasifica objetos celestes en tres categorÃ­as:
- **Galaxy** (0): Galaxias
- **OSO** (1): Objetos Quasi-estelares (Quasars)  
- **Star** (2): Estrellas

### Componentes del Sistema Original:
- **DAG en Apache Airflow**: `process_et_stellar_data` para preprocesamiento y normalizaciÃ³n
- **ExperimentaciÃ³n con MLflow**: OptimizaciÃ³n de hiperparÃ¡metros usando Optuna
- **Modelo Productivo**: Artefacto `model.pkl` servido via API
- **API REST**: Endpoint FastAPI para predicciones

### Nuevas Funcionalidades Implementadas:
âœ… **GraphQL API**: Consultas flexibles y tipado fuerte  
âœ… **gRPC Service**: Alto rendimiento con Protocol Buffers  
âœ… **Kafka Streaming**: Procesamiento en tiempo real  
âœ… **Multi-Protocol Support**: Una aplicaciÃ³n, cuatro protocolos  
âœ… **Performance Benchmarking**: ComparaciÃ³n automÃ¡tica de rendimiento

---

## Arquitectura del Sistema

![Aqritectura del sistema](./img/workflow.png)


---

## Estructura del Proyecto

```
tp-amq2-service-ml/
tp-amq2-service-ml/
â”œâ”€â”€ airflow/ # Apache Airflow DAGs y configuraciÃ³n
â”‚ â”œâ”€â”€ dags/
â”‚ â”‚ â”œâ”€â”€ etl_process_grupal.py # DAG principal de ETL
â”‚ â”‚ â””â”€â”€ retrain_the_model.py # DAG de reentrenamiento
â”‚ â””â”€â”€ secrets/ # ConfiguraciÃ³n de conexiones y variables
â”‚
â”œâ”€â”€ fastapi/ # Servicio principal multi-protocolo
â”‚ â”œâ”€â”€ app.py # FastAPI principal con GraphQL
â”‚ â”œâ”€â”€ graphql_schema.py # Schema GraphQL para clasificaciÃ³n
â”‚ â”œâ”€â”€ grpc_server.py # Servidor gRPC con streaming
â”‚ â”œâ”€â”€ kafka_streaming.py # Consumidor/Productor Kafka
â”‚ â”œâ”€â”€ model_manager.py # GestiÃ³n centralizada del modelo ML
â”‚ â”œâ”€â”€ proto/ # Protocol Buffers definitions
â”‚ â”‚ â””â”€â”€ star_classification.proto
â”‚ â”œâ”€â”€ requirements.txt # Dependencias multi-protocolo
â”‚ â”œâ”€â”€ Dockerfile # Build con generaciÃ³n gRPC
â”‚ â””â”€â”€ files/
â”‚ â”œâ”€â”€ model.pkl # Modelo ML productivo
â”‚ â””â”€â”€ data_star.json # Metadatos del pipeline
â”‚
â”œâ”€â”€ frontend/ # AplicaciÃ³n React con MUI y Vite
â”‚ â”œâ”€â”€ public/ # Archivos pÃºblicos (favicon, index.html)
â”‚ â”œâ”€â”€ src/ # Componentes y vistas
â”‚ â”‚ â”œâ”€â”€ components/ # Componentes como InputForm, HistoryList, etc.
â”‚ â”‚ â”œâ”€â”€ App.tsx # App principal
â”‚ â”‚ â”œâ”€â”€ main.tsx # Punto de entrada
â”‚ â”‚ â”œâ”€â”€ theme.ts # Tema MUI personalizado
â”‚ â”‚ â””â”€â”€ index.css # Estilos globales
â”‚ â”œâ”€â”€ package.json # Dependencias frontend
â”‚ â””â”€â”€ vite.config.ts # ConfiguraciÃ³n Vite
â”‚
â”œâ”€â”€ notebook_example/ # Notebooks experimentaciÃ³n
â”‚ â”œâ”€â”€ experiment_mlflow.py # Experimentos MLflow + Optuna
â”‚ â”œâ”€â”€ mlflow_aux.py # Utilidades MLflow
â”‚ â””â”€â”€ plots.py # Visualizaciones
â”‚
â”œâ”€â”€ resources/ # Ejemplos de implementaciÃ³n
â”‚ â”œâ”€â”€ gRPC_GraphQL_REST.py # Tutorial implementaciones
â”‚ â””â”€â”€ data_streaming1_kafka.py # Ejemplo Kafka streaming
â”‚
â”œâ”€â”€ docker-compose.yaml # OrquestaciÃ³n multi-servicio
â”œâ”€â”€ test_clients.py # Cliente de testing multi-protocolo
â”œâ”€â”€ API_USAGE_GUIDE.md # GuÃ­a detallada de uso
â””â”€â”€ README.md                       # Este archivo
```

---

## InstalaciÃ³n y Despliegue
---

## âš™ï¸ ConfiguraciÃ³n Inicial

Antes de iniciar el proyecto, debÃ©s crear el archivo `.env` dentro de la carpeta `frontend/`, copiando el contenido desde `.env.example`:

```bash
# root
cp .env.example .env

# frontend
cd frontend
cp .env.example .env
```

### 1. Despliegue Completo (Todos los Servicios incluyendo el frontend)
```bash
# Todos los servicios incluido Kafka streaming y el frontend
docker compose --profile all up -d
```

### 2. Despliegue por Perfiles
```bash
# Solo servicios de ML (MLflow + API)
docker compose --profile mlflow up -d

# Con soporte de streaming (incluye Kafka)
docker compose --profile streaming up -d

# Solo pipeline de datos (Airflow)
docker compose --profile airflow up -d
```

### 3. VerificaciÃ³n de Servicios

| Servicio | URL | DescripciÃ³n |
|----------|-----|-------------|
| **ğŸŒ API Multi-Protocol** | http://localhost:8800/ | FastAPI principal con todos los protocolos |
| **ğŸ“Š API Documentation** | http://localhost:8800/docs | DocumentaciÃ³n Swagger interactiva |
| **ğŸ” Services Info** | http://localhost:8800/services | InformaciÃ³n de todos los protocolos |
| **âš¡ GraphQL Playground** | http://localhost:8800/graphql | Interface GraphQL interactiva |
| **ğŸ—ï¸ Apache Airflow** | http://localhost:8080 | GestiÃ³n de flujos de trabajo |
| **ğŸ”¬ MLflow** | http://localhost:5000 | GestiÃ³n del ciclo de vida ML |
| **ğŸ’¾ MinIO** | http://localhost:9001 | Almacenamiento de objetos S3 |
| **ğŸš€ Frontend en React**| http://localhost:5174 | Interfaz futurista para clasificaciÃ³n de galaxias servido en Vite |


### 4. Puertos Expuestos
- **8800**: FastAPI (REST + GraphQL)
- **50051**: gRPC Service
- **9092**: Kafka Broker (conexiones externas)
- **9094**: Kafka Broker (conexiones internas)
- **2181**: Zookeeper
- **5000**: MLflow Tracking Server
- **8080**: Airflow Webserver
- **9001**: MinIO Console
- **5174**: Frontend servido en Vite

---
## Levantar el frontend localmente (developer mode)

Para correr la interfaz futurista de clasificaciÃ³n de galaxias en modo desarrollo:

```bash
# 1. Moverse a la carpeta del frontend
cd frontend

# 2. Instalar dependencias
npm install

# 3. Iniciar servidor de desarrollo
npm run dev
```

## Uso de la API

La API ahora soporta **4 protocolos diferentes** para la clasificaciÃ³n de objetos estelares. Puedes elegir el que mejor se adapte a tus necesidades.

### Datos de Ejemplo
```json
{
    "obj_ID": 1237663784734294016.0,
    "alpha": 135.689,
    "delta": 32.494,
    "u": 23.87882,
    "g": 22.27530,
    "r": 20.39398,
    "i": 19.16763,
    "z": 18.79371,
    "run_ID": 3606,
    "cam_col": 4,
    "field_ID": 587,
    "spec_obj_ID": 6.543777825301504e17,
    "redshift": 0.644,
    "plate": 5812,
    "MJD": 56354,
    "fiber_ID": 171
}
```

### 1. ğŸ”— REST API (HTTP)

**Python:**
```python
import requests

response = requests.post(
    "http://localhost:8800/predict/",
    json={"features": {
        "obj_ID": 1237663784734294016.0,
        "alpha": 135.689,
        # ... resto de campos
    }}
)
print(response.json())
```

**Bash/cURL:**
```bash
curl -X POST "http://localhost:8800/predict/" \
  -H "Content-Type: application/json" \
  -d '{
    "features": {
        "obj_ID": 1237663784734294016.0,
        "alpha": 135.689,
        "delta": 32.494,
        "u": 23.87882,
        "g": 22.27530,
        "r": 20.39398,
        "i": 19.16763,
        "z": 18.79371,
        "run_ID": 3606,
        "cam_col": 4,
        "field_ID": 587,
        "spec_obj_ID": 6.543777825301504e17,
        "redshift": 0.644,
        "plate": 5812,
        "MJD": 56354,
        "fiber_ID": 171
    }
  }'
```

### 2. âš¡ GraphQL API

**Acceso al playground interactivo:** http://localhost:8800/graphql

**Ejemplo de Mutation:**
```graphql
mutation PredictStar {
  predict(features: {
    objID: 1237663784734294016.0,
    alpha: 135.689,
    delta: 32.494,
    u: 23.87882,
    g: 22.27530,
    r: 20.39398,
    i: 19.16763,
    z: 18.79371,
    runID: 3606,
    camCol: 4,
    fieldID: 587,
    specObjID: 6.543777825301504e17,
    redshift: 0.644,
    plate: 5812,
    MJD: 56354,
    fiberID: 171
  }) {
    intOutput
    strOutput
  }
}
```

**Python con requests:**
```python
import requests

query = """
mutation PredictStar($features: StarClassificationInput!) {
    predict(features: $features) {
        intOutput
        strOutput
    }
}
"""

variables = {"features": {
    "objID": 1237663784734294016.0,
    "alpha": 135.689,
    # ... resto de campos
}}

response = requests.post(
    "http://localhost:8800/graphql",
    json={"query": query, "variables": variables}
)
```

### 3. ğŸš€ gRPC Service

**Generar archivos Python del proto:**
```bash
cd dockerfiles/fastapi
python -m grpc_tools.protoc \
  -I./proto \
  --python_out=. \
  --grpc_python_out=. \
  ./proto/star_classification.proto
```

**Cliente Python:**
```python
import grpc
import star_classification_pb2
import star_classification_pb2_grpc

# ConexiÃ³n
channel = grpc.insecure_channel('localhost:50051')
stub = star_classification_pb2_grpc.StarClassificationServiceStub(channel)

# PredicciÃ³n individual
request = star_classification_pb2.StarFeatures(
    obj_ID=1237663784734294016.0,
    alpha=135.689,
    delta=32.494,
    # ... resto de campos
)

response = stub.Predict(request)
print(f"PredicciÃ³n: {response.int_output} ({response.str_output})")

# Health check
health_response = stub.HealthCheck(
    star_classification_pb2.HealthCheckRequest()
)
print(f"Estado: {health_response.status}")

# Streaming (multiple predictions)
requests = [request] * 5
for response in stub.PredictStream(iter(requests)):
    print(f"Stream: {response.int_output} ({response.str_output})")
```

### 4. ğŸ“¡ Kafka Streaming

**Enviar datos para predicciÃ³n:**
```python
from kafka import KafkaProducer
import json

producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    value_serializer=lambda x: json.dumps(x).encode('utf-8')
)

data = {
    "obj_ID": 1237663784734294016.0,
    "alpha": 135.689,
    # ... resto de campos
}

producer.send('star_features_input', value=data)
producer.flush()
```

**Recibir predicciones:**
```python
from kafka import KafkaConsumer
import json

consumer = KafkaConsumer(
    'star_predictions_output',
    bootstrap_servers=['localhost:9092'],
    value_deserializer=lambda x: json.loads(x.decode('utf-8'))
)

for message in consumer:
    prediction = message.value
    print(f"PredicciÃ³n recibida: {prediction}")
```

**Endpoint de testing:**
```bash
curl -X POST "http://localhost:8800/stream/test" \
  -H "Content-Type: application/json" \
  -d '{
    "obj_ID": 1237663784734294016.0,
    "alpha": 135.689,
    "delta": 32.494,
    "u": 23.87882,
    "g": 22.27530,
    "r": 20.39398,
    "i": 19.16763,
    "z": 18.79371,
    "run_ID": 3606,
    "cam_col": 4,
    "field_ID": 587,
    "spec_obj_ID": 6.543777825301504e17,
    "redshift": 0.644,
    "plate": 5812,
    "MJD": 56354,
    "fiber_ID": 171
  }'
```

---

## ComparaciÃ³n de Protocolos

| Aspecto | REST | GraphQL | gRPC | Kafka Streaming |
|---------|------|---------|------|----------------|
| **ğŸš€ Latencia** | Media | Media | Baja | Alta (async) |
| **ğŸ“ˆ Throughput** | Medio | Medio | Alto | Muy Alto |
| **ğŸ“¡ Streaming** | No | Limitado | SÃ­ (bidireccional) | SÃ­ (tiempo real) |
| **ğŸ”§ Facilidad de uso** | Alta | Media | Baja | Media |
| **ğŸ“ Tipado fuerte** | SÃ­ (Pydantic) | SÃ­ (Schema) | SÃ­ (Protobuf) | No |
| **ğŸŒ Compatibilidad** | Universal | Web/Mobile | Multiplataforma | Sistemas distribuidos |
| **âš™ï¸ Complejidad setup** | Baja | Baja | Media | Alta |
| **ğŸ“Š Debugging** | FÃ¡cil | FÃ¡cil | DifÃ­cil | Medio |

### Casos de Uso Recomendados:

- **ğŸ”— REST API**: Integraciones simples, APIs pÃºblicas, desarrollo web tradicional
- **âš¡ GraphQL**: Dashboards complejos, aplicaciones mÃ³viles, consultas flexibles
- **ğŸš€ gRPC**: ComunicaciÃ³n entre microservicios, sistemas de alta performance, streaming
- **ğŸ“¡ Kafka**: Procesamiento en tiempo real, sistemas distribuidos, alta escala

---

## Testing y Benchmarking

### Cliente de Pruebas Unificado

El proyecto incluye un cliente completo para probar todos los protocolos:

```bash
python test_clients.py
```

**Funcionalidades del cliente:**
- âœ… Testing individual de cada protocolo
- âœ… Benchmarking automÃ¡tico de performance
- âœ… ComparaciÃ³n lado a lado
- âœ… MediciÃ³n de latencia y throughput
- âœ… GeneraciÃ³n de reportes

### Ejemplo de Salida del Benchmark:
```
============================================================
STAR CLASSIFICATION API PERFORMANCE COMPARISON
============================================================

Testing REST API with 100 requests...
  First response: {'int_output': 2, 'str_output': 'Star'}

Testing GraphQL API with 100 requests...
  First response: {'data': {'predict': {'intOutput': 2, 'strOutput': 'Star'}}}

Testing gRPC service with 100 requests...
  First response: {'int_output': 2, 'str_output': 'Star'}

Testing Kafka streaming with 10 messages...
  First response: {'prediction': {'int_output': 2, 'str_output': 'Star'}}

============================================================
PERFORMANCE SUMMARY
============================================================
Service              Avg Time (ms)   Req/Sec         Success Rate
------------------------------------------------------------
REST                 45.23          22.11           100/100
GraphQL              52.18          19.17           100/100
gRPC                 23.45          42.65           100/100
Kafka Streaming      125.67         7.95            10/10
```

### MÃ©tricas Disponibles:
- **Latencia promedio**: Tiempo de respuesta por peticiÃ³n
- **Throughput**: Peticiones/mensajes por segundo
- **Tasa de Ã©xito**: Porcentaje de peticiones exitosas
- **Uso de recursos**: CPU y memoria durante las pruebas

---

## Archivos Clave del Proyecto

### ğŸš€ Servicio Principal
- **`dockerfiles/fastapi/app.py`**: FastAPI principal con GraphQL integrado
- **`dockerfiles/fastapi/requirements.txt`**: Dependencias multi-protocolo
- **`dockerfiles/fastapi/Dockerfile`**: Build con generaciÃ³n automÃ¡tica gRPC

### ğŸ”— GraphQL
- **`dockerfiles/fastapi/graphql_schema.py`**: Schema completo con tipos y mutations
- **Endpoint**: `/graphql` con playground interactivo

### âš¡ gRPC
- **`dockerfiles/fastapi/proto/star_classification.proto`**: DefiniciÃ³n Protocol Buffers
- **`dockerfiles/fastapi/grpc_server.py`**: Servidor gRPC con streaming support
- **Puerto**: `50051` para conexiones gRPC

### ğŸ“¡ Kafka Streaming
- **`dockerfiles/fastapi/kafka_streaming.py`**: Producer/Consumer para ML streaming
- **Topics**: `star_features_input`, `star_predictions_output`
- **ConfiguraciÃ³n**: Auto-conecta con Kafka broker

### ğŸ§ª Testing
- **`test_clients.py`**: Cliente unificado para todos los protocolos
- **`API_USAGE_GUIDE.md`**: GuÃ­a detallada de uso y ejemplos

### ğŸ”§ Infraestructura
- **`docker-compose.yaml`**: OrquestaciÃ³n completa con perfiles
- **Perfiles disponibles**: `all`, `mlflow`, `airflow`, `streaming`

---

## Troubleshooting

### Problemas Comunes:

**âŒ Error: gRPC port already in use**
```bash
# Verificar quÃ© proceso usa el puerto
lsof -i :50051
# Matar proceso si es necesario
kill -9 <PID>
```

**âŒ Error: Kafka broker not available**
```bash
# Verificar servicios Kafka
docker compose ps
# Reiniciar servicios Kafka
docker compose restart kafka zookeeper
```

**âŒ Error: GraphQL schema not found**
```bash
# Reconstruir contenedor FastAPI
docker compose build fastapi
docker compose up -d fastapi
```

**âŒ Error: gRPC proto files missing**
```bash
# Generar archivos proto manualmente
cd dockerfiles/fastapi
python -m grpc_tools.protoc -I./proto --python_out=. --grpc_python_out=. ./proto/star_classification.proto
```

### VerificaciÃ³n de Servicios:
```bash
# Estado de contenedores
docker compose ps

# Logs de un servicio especÃ­fico
docker compose logs fastapi

# Restart de servicios
docker compose restart fastapi kafka

# Cleanup completo
docker compose down --volumes --rmi all
```

---

## Consideraciones de ProducciÃ³n

### ğŸ”’ Seguridad
- [ ] Implementar autenticaciÃ³n JWT
- [ ] Agregar autorizaciÃ³n por roles
- [ ] SSL/TLS para todas las conexiones
- [ ] Rate limiting por protocolo

### ğŸ“Š Monitoreo
- [ ] MÃ©tricas con Prometheus
- [ ] Dashboards en Grafana
- [ ] Alerting automÃ¡tico
- [ ] Logging distribuido

### ğŸš€ Escalabilidad
- [ ] Load balancer para FastAPI
- [ ] MÃºltiples replicas gRPC
- [ ] Particionado Kafka
- [ ] Auto-scaling por demanda

### ğŸ”„ DevOps
- [ ] CI/CD pipelines
- [ ] Tests automatizados
- [ ] Deployment blue-green
- [ ] Rollback automÃ¡tico

---

## PrÃ³ximos Pasos

1. **ğŸ” AutenticaciÃ³n**: Implementar JWT across todos los protocolos
2. **ğŸ“Š Monitoring**: Agregar Prometheus + Grafana stack
3. **ğŸ§ª Testing**: Implementar tests unitarios e integraciÃ³n
4. **ğŸ“š SDKs**: Crear clients SDKs para mÃºltiples lenguajes
5. **âš¡ OptimizaciÃ³n**: Optimizar performance y resource usage
6. **ğŸŒ Documentation**: API documentation multilenguaje

---

## Contribuidores y Licencia

**Integrantes del Proyecto:**
- Noelia Qualindi
- Trinidad Monreal 
- Fabian Sarmiento
- Matias Marando
- Jorge Valdez

**InstituciÃ³n:** FIUBA - MaestrÃ­a en Inteligencia Artificial

**Curso:** Trabajo PrÃ¡ctico Integrador - Operaciones de Aprendizaje AutomÃ¡tico II

**Fecha:** 2025

---

*Para preguntas o soporte tÃ©cnico, consultar el `API_USAGE_GUIDE.md` o crear un issue en el repositorio.*